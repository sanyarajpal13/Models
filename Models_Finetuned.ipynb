{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanyarajpal13/Models/blob/main/Models_Finetuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZphn3hPR7Pb",
        "outputId": "bf09e0b1-4787-4596-fbf9-ff15457dc1ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Data-GP1.csv: 209697 rows -> 209697 after dropping rows without price/count.\n",
            "Saved cleaned CSV to: /mnt/data/gp1_outputs/Data-GP1-cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Demand estimation pipeline for Data-GP1\n",
        "# Full EDA, feature engineering, modeling, diagnostics, and outputs\n",
        "# =============================================================================\n",
        "\n",
        "# 0) Imports\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from patsy import dmatrix\n",
        "from statsmodels.iolib.summary2 import summary_col\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# For VIF\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Make figures prettier\n",
        "sns.set(style=\"whitegrid\", context=\"talk\")\n",
        "plt.rcParams['figure.dpi'] = 120\n",
        "\n",
        "# Output directory\n",
        "OUT = \"/mnt/data/gp1_outputs\"\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Load and initial clean\n",
        "# ---------------------------\n",
        "def load_and_clean(path=\"Data-GP1.csv\"):\n",
        "    df = pd.read_csv(path)\n",
        "    # Ensure known columns exist; if not, user must check CSV header\n",
        "    # Convert dates\n",
        "    for c in [\"Dept_Date\",\"Purchase_Date\"]:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
        "    # Compute days to departure\n",
        "    if \"Dept_Date\" in df.columns and \"Purchase_Date\" in df.columns:\n",
        "        df[\"days_to_departure\"] = (df[\"Dept_Date\"] - df[\"Purchase_Date\"]).dt.days\n",
        "    else:\n",
        "        df[\"days_to_departure\"] = np.nan\n",
        "    # Basic numeric conversions & safety\n",
        "    if \"mean_net_ticket_price\" in df.columns:\n",
        "        df[\"mean_net_ticket_price\"] = pd.to_numeric(df[\"mean_net_ticket_price\"], errors=\"coerce\")\n",
        "    if \"num_seats_total\" in df.columns:\n",
        "        df[\"num_seats_total\"] = pd.to_numeric(df[\"num_seats_total\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    # Drop rows with missing core vars (we keep them but save count)\n",
        "    pre_n = len(df)\n",
        "    df = df.dropna(subset=[\"mean_net_ticket_price\",\"num_seats_total\"])\n",
        "    print(f\"Loaded {path}: {pre_n} rows -> {len(df)} after dropping rows without price/count.\")\n",
        "    return df\n",
        "\n",
        "df = load_and_clean()\n",
        "\n",
        "# Save cleaned snapshot\n",
        "df.to_csv(os.path.join(OUT,\"Data-GP1-cleaned.csv\"), index=False)\n",
        "print(\"Saved cleaned CSV to:\", os.path.join(OUT,\"Data-GP1-cleaned.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rth-RegtShAd",
        "outputId": "cd9a2a5a-c220-455c-d568-6bca28ca306f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature engineered. Columns now: ['num_seats_total', 'mean_net_ticket_price', 'Dept_Date', 'Purchase_Date', 'Train_Number_All', 'Culmulative_sales', 'isNormCabin', 'isReturn', 'isOneway', 'Customer_Cat', 'days_to_departure', 'log_price', 'log_num_seats_total', 'booking_window', 'dept_month', 'dept_weekday', 'dept_ym', 'price_bucket', 'train_freq']\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 2) Feature engineering (expand features to improve explanatory power)\n",
        "# ---------------------------\n",
        "def engineer_features(df):\n",
        "    # Basic logs\n",
        "    df = df.copy()\n",
        "    # avoid log(0) â€” earlier we saw num_seats_total >=1\n",
        "    df[\"log_price\"] = np.log(df[\"mean_net_ticket_price\"].replace(0, np.nan))\n",
        "    df[\"log_num_seats_total\"] = np.log(df[\"num_seats_total\"].astype(float).replace(0, np.nan))\n",
        "    # booking window buckets\n",
        "    df[\"booking_window\"] = pd.cut(df[\"days_to_departure\"].fillna(-1),\n",
        "                                  bins=[-1,0,3,14,60,365],\n",
        "                                  labels=[\"missing_or_day\", \"last_0d\", \"0-3d\", \"4-14d\",\"15-60d\"])\n",
        "    # temporal features\n",
        "    if \"Dept_Date\" in df.columns:\n",
        "        df[\"dept_month\"] = df[\"Dept_Date\"].dt.month\n",
        "        df[\"dept_weekday\"] = df[\"Dept_Date\"].dt.dayofweek  # 0=Mon ... 6=Sun\n",
        "        df[\"dept_ym\"] = df[\"Dept_Date\"].dt.to_period(\"M\").astype(str)\n",
        "    # price buckets (useful for binned plots)\n",
        "    df[\"price_bucket\"] = pd.qcut(df[\"mean_net_ticket_price\"], 10, duplicates=\"drop\")\n",
        "    # training count per Train_Number_All (popularity measure)\n",
        "    if \"Train_Number_All\" in df.columns:\n",
        "        train_counts = df[\"Train_Number_All\"].value_counts().to_dict()\n",
        "        df[\"train_freq\"] = df[\"Train_Number_All\"].map(train_counts).fillna(0)\n",
        "    # fill NA for binary flags if present\n",
        "    for col in [\"isNormCabin\",\"isReturn\",\"isOneway\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna(0).astype(int)\n",
        "    return df\n",
        "\n",
        "df = engineer_features(df)\n",
        "print(\"Feature engineered. Columns now:\", df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmmRjKYzSuYz",
        "outputId": "e6885156-f316-47f0-9757-3003880222b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved descriptive stats to eda_describe.csv\n",
            "Saved missingness to eda_missingness.csv\n",
            "EDA plots and CSVs saved in: /mnt/data/gp1_outputs\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 3) Very detailed EDA (save many plots + summary tables)\n",
        "# ---------------------------\n",
        "def detailed_eda(df, outdir=OUT, sample_for_scatter=20000):\n",
        "    # 3.1 Summary tables\n",
        "    desc = df.describe(include='all').T\n",
        "    desc.to_csv(os.path.join(outdir,\"eda_describe.csv\"))\n",
        "    print(\"Saved descriptive stats to eda_describe.csv\")\n",
        "\n",
        "    # 3.2 Missingness\n",
        "    miss = df.isnull().sum().sort_values(ascending=False)\n",
        "    miss.to_csv(os.path.join(outdir,\"eda_missingness.csv\"))\n",
        "    print(\"Saved missingness to eda_missingness.csv\")\n",
        "\n",
        "    # 3.3 Price distribution (log + raw)\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.histplot(df[\"mean_net_ticket_price\"].clip(upper=df[\"mean_net_ticket_price\"].quantile(0.99)),\n",
        "                 bins=80, kde=True)\n",
        "    plt.title(\"Ticket price distribution (clipped 99th pct)\")\n",
        "    plt.xlabel(\"mean_net_ticket_price\")\n",
        "    plt.savefig(os.path.join(outdir,\"price_dist.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.histplot(np.log(df[\"mean_net_ticket_price\"].replace(0,np.nan)).dropna(), bins=60, kde=True)\n",
        "    plt.title(\"Log price distribution\")\n",
        "    plt.savefig(os.path.join(outdir,\"log_price_dist.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # 3.4 Seats distribution\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.countplot(x=\"num_seats_total\", data=df[df[\"num_seats_total\"]<=20])\n",
        "    plt.title(\"Seats sold distribution (trimmed at 20)\")\n",
        "    plt.savefig(os.path.join(outdir,\"seats_dist.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # 3.5 Scatter sample Price vs Seats (sample for speed)\n",
        "    sample = df.sample(n=min(len(df), sample_for_scatter), random_state=1)\n",
        "    plt.figure(figsize=(7,5))\n",
        "    sns.scatterplot(x=\"mean_net_ticket_price\", y=\"num_seats_total\", data=sample, alpha=0.15)\n",
        "    plt.ylim(0, df[\"num_seats_total\"].quantile(0.99))\n",
        "    plt.title(\"Price vs Seats (sample)\")\n",
        "    plt.savefig(os.path.join(outdir,\"scatter_price_vs_seats_sample.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # 3.6 Binned averages (price buckets)\n",
        "    gb = df.groupby(\"price_bucket\").agg(mean_price=(\"mean_net_ticket_price\",\"mean\"),\n",
        "                                        mean_seats=(\"num_seats_total\",\"mean\"),\n",
        "                                        count=(\"num_seats_total\",\"count\")).reset_index()\n",
        "    gb.to_csv(os.path.join(outdir,\"binned_price_meanseats.csv\"), index=False)\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    sns.lineplot(x=\"mean_price\", y=\"mean_seats\", data=gb, marker=\"o\")\n",
        "    plt.title(\"Binned mean seats by mean price (10 quantiles)\")\n",
        "    plt.savefig(os.path.join(outdir,\"binned_price_meanseats.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # 3.7 Days to departure patterns\n",
        "    plt.figure(figsize=(7,4))\n",
        "    sns.histplot(df[\"days_to_departure\"].clip(lower=0, upper=365), bins=60)\n",
        "    plt.title(\"Days to departure (0-365)\")\n",
        "    plt.savefig(os.path.join(outdir,\"days_to_departure_dist.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # 3.8 Average seats by booking window\n",
        "    if \"booking_window\" in df.columns:\n",
        "        plt.figure(figsize=(7,4))\n",
        "        order = df['booking_window'].cat.categories if hasattr(df['booking_window'], \"cat\") else sorted(df['booking_window'].unique())\n",
        "        sns.barplot(x=\"booking_window\", y=\"num_seats_total\", data=df, order=order, estimator=np.mean)\n",
        "        plt.title(\"Average seats by booking window\")\n",
        "        plt.savefig(os.path.join(outdir,\"avg_seats_by_booking_window.png\"), bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "    # 3.9 Category comparisons\n",
        "    for col in [\"Customer_Cat\",\"isOneway\",\"isReturn\",\"isNormCabin\"]:\n",
        "        if col in df.columns:\n",
        "            plt.figure(figsize=(7,4))\n",
        "            sns.barplot(x=col, y=\"num_seats_total\", data=df, estimator=np.mean)\n",
        "            plt.title(f\"Average seats by {col}\")\n",
        "            plt.savefig(os.path.join(outdir,f\"avg_seats_by_{col}.png\"), bbox_inches=\"tight\")\n",
        "            plt.close()\n",
        "\n",
        "    # 3.10 Top trains\n",
        "    if \"Train_Number_All\" in df.columns:\n",
        "        top_trains = df[\"Train_Number_All\"].value_counts().head(20)\n",
        "        top_trains.to_csv(os.path.join(outdir,\"top_20_trains_counts.csv\"), index=True, header=True)\n",
        "        plt.figure(figsize=(8,6))\n",
        "        sns.barplot(y=top_trains.index, x=top_trains.values)\n",
        "        plt.title(\"Top 20 train counts (observations)\")\n",
        "        plt.savefig(os.path.join(outdir,\"top_20_trains.png\"), bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "    # 3.11 Correlation heatmap (numeric)\n",
        "    numeric_cols = [\"num_seats_total\",\"mean_net_ticket_price\",\"days_to_departure\"]\n",
        "    corr = df[numeric_cols].corr()\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "    plt.title(\"Numeric correlation\")\n",
        "    plt.savefig(os.path.join(outdir,\"correlation_numeric.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    print(\"EDA plots and CSVs saved in:\", outdir)\n",
        "\n",
        "# Run EDA\n",
        "detailed_eda(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzMpBFALS7P_",
        "outputId": "d62382cf-814e-4ccb-bc3b-7d60845ac975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique trains: 15\n",
            "OLS formula: log_num_seats_total ~ log_price + days_to_departure + I(days_to_departure**2) + isNormCabin + isReturn + isOneway + C(Customer_Cat) + log_price:C(Customer_Cat) + C(Train_Number_All)\n",
            "                             OLS Regression Results                            \n",
            "===============================================================================\n",
            "Dep. Variable:     log_num_seats_total   R-squared:                       0.145\n",
            "Model:                             OLS   Adj. R-squared:                  0.145\n",
            "Method:                  Least Squares   F-statistic:                     1726.\n",
            "Date:                 Sun, 14 Sep 2025   Prob (F-statistic):               0.00\n",
            "Time:                         08:17:34   Log-Likelihood:            -1.9448e+05\n",
            "No. Observations:               209697   AIC:                         3.890e+05\n",
            "Df Residuals:                   209674   BIC:                         3.892e+05\n",
            "Df Model:                           22                                         \n",
            "Covariance Type:                   HC3                                         \n",
            "==================================================================================================\n",
            "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Intercept                         -1.0740      0.036    -29.544      0.000      -1.145      -1.003\n",
            "C(Customer_Cat)[T.B]               2.6712      0.033     79.973      0.000       2.606       2.737\n",
            "C(Train_Number_All)[T.B]           0.1448      0.007     19.355      0.000       0.130       0.159\n",
            "C(Train_Number_All)[T.C]           0.0758      0.008      9.387      0.000       0.060       0.092\n",
            "C(Train_Number_All)[T.D]          -0.0070      0.008     -0.867      0.386      -0.023       0.009\n",
            "C(Train_Number_All)[T.E]           0.1875      0.007     27.811      0.000       0.174       0.201\n",
            "C(Train_Number_All)[T.F]           0.1281      0.007     18.170      0.000       0.114       0.142\n",
            "C(Train_Number_All)[T.G]           0.1049      0.008     13.885      0.000       0.090       0.120\n",
            "C(Train_Number_All)[T.H]           0.1313      0.007     18.715      0.000       0.118       0.145\n",
            "C(Train_Number_All)[T.I]           0.0321      0.008      4.166      0.000       0.017       0.047\n",
            "C(Train_Number_All)[T.J]           0.0177      0.007      2.397      0.017       0.003       0.032\n",
            "C(Train_Number_All)[T.K]          -0.0575      0.009     -6.384      0.000      -0.075      -0.040\n",
            "C(Train_Number_All)[T.L]        2.133e-05      0.009      0.002      0.998      -0.017       0.017\n",
            "C(Train_Number_All)[T.M]          -0.1043      0.008    -13.365      0.000      -0.120      -0.089\n",
            "C(Train_Number_All)[T.N]          -0.1927      0.010    -20.203      0.000      -0.211      -0.174\n",
            "C(Train_Number_All)[T.O]          -0.3384    216.409     -0.002      0.999    -424.492     423.816\n",
            "log_price                          0.2191      0.006     35.382      0.000       0.207       0.231\n",
            "log_price:C(Customer_Cat)[T.B]    -0.4177      0.006    -69.745      0.000      -0.429      -0.406\n",
            "days_to_departure                  0.0006   7.65e-05      8.200      0.000       0.000       0.001\n",
            "I(days_to_departure ** 2)       5.934e-07   2.93e-07      2.028      0.043       2e-08    1.17e-06\n",
            "isNormCabin                       -0.0024      0.004     -0.603      0.547      -0.010       0.005\n",
            "isReturn                           0.0231      0.004      5.321      0.000       0.015       0.032\n",
            "isOneway                          -0.0875      0.004    -21.130      0.000      -0.096      -0.079\n",
            "==============================================================================\n",
            "Omnibus:                    12597.292   Durbin-Watson:                   1.768\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            15022.687\n",
            "Skew:                           0.655   Prob(JB):                         0.00\n",
            "Kurtosis:                       2.943   Cond. No.                     8.08e+06\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
            "[2] The condition number is large, 8.08e+06. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 4) Model formulas (safe building) & baseline models\n",
        "# ---------------------------\n",
        "\n",
        "# Build base formulas safely: use only columns that exist\n",
        "base_controls = [\"days_to_departure\", \"I(days_to_departure**2)\", \"isNormCabin\", \"isReturn\", \"isOneway\"]\n",
        "formula_ols = \"log_num_seats_total ~ log_price + \" + \" + \".join(base_controls)\n",
        "\n",
        "# interactions with Customer_Cat if present\n",
        "if \"Customer_Cat\" in df.columns:\n",
        "    formula_ols += \" + C(Customer_Cat) + log_price:C(Customer_Cat)\"\n",
        "\n",
        "# add train fixed effects only when number of unique trains is reasonable\n",
        "if \"Train_Number_All\" in df.columns:\n",
        "    n_trains = df[\"Train_Number_All\"].nunique()\n",
        "    print(\"Unique trains:\", n_trains)\n",
        "    if n_trains <= 200:\n",
        "        formula_ols += \" + C(Train_Number_All)\"\n",
        "    else:\n",
        "        # keep top 30 trains as dummies to control popularity; label rest 'other'\n",
        "        top_tr = df[\"Train_Number_All\"].value_counts().nlargest(30).index\n",
        "        df[\"Train_top30\"] = df[\"Train_Number_All\"].where(df[\"Train_Number_All\"].isin(top_tr), other=\"Other\")\n",
        "        formula_ols += \" + C(Train_top30)\"\n",
        "\n",
        "print(\"OLS formula:\", formula_ols)\n",
        "\n",
        "# OLS estimation (robust SEs)\n",
        "ols_df = df.dropna(subset=[\"log_num_seats_total\",\"log_price\",\"days_to_departure\"])\n",
        "ols_model = smf.ols(formula=formula_ols, data=ols_df).fit(cov_type=\"HC3\")\n",
        "print(ols_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU1xvjywTPeR",
        "outputId": "bc6ed722-db34-467b-8361-d649a927708a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Breusch-Pagan test: {'LM stat': np.float64(7644.405646366074), 'LM pvalue': np.float64(0.0), 'F stat': np.float64(360.5796335588272), 'F pvalue': np.float64(0.0)}\n",
            "Saved VIF table to ols_vif.csv\n",
            "{'LM stat': np.float64(7644.405646366074), 'LM pvalue': np.float64(0.0), 'F stat': np.float64(360.5796335588272), 'F pvalue': np.float64(0.0)}\n",
            "                          variable          VIF\n",
            "0                        Intercept  1127.051967\n",
            "1             C(Customer_Cat)[T.B]   178.420836\n",
            "17  log_price:C(Customer_Cat)[T.B]   148.848071\n",
            "18               days_to_departure    12.623372\n",
            "16                       log_price    11.992422\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 5) Diagnostics for OLS (tests & plots)\n",
        "# ---------------------------\n",
        "def ols_diagnostics(model, df_out=OUT):\n",
        "    resid = model.resid\n",
        "    fitted = model.fittedvalues\n",
        "\n",
        "    # Residuals vs fitted\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.scatter(fitted, resid, alpha=0.2)\n",
        "    plt.axhline(0, color='red', ls='--')\n",
        "    plt.xlabel(\"Fitted\")\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.title(\"Residuals vs Fitted\")\n",
        "    plt.savefig(os.path.join(df_out,\"ols_resid_vs_fitted.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # Histogram\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.hist(resid, bins=60)\n",
        "    plt.title(\"OLS residuals histogram\")\n",
        "    plt.savefig(os.path.join(df_out,\"ols_resid_hist.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # Q-Q plot\n",
        "    plt.figure(figsize=(6,4))\n",
        "    stats.probplot(resid, dist=\"norm\", plot=plt)\n",
        "    plt.title(\"OLS residuals Q-Q\")\n",
        "    plt.savefig(os.path.join(df_out,\"ols_resid_qq.png\"), bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # Breusch-Pagan test for heteroskedasticity\n",
        "    from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "    bp_test = het_breuschpagan(resid, model.model.exog)\n",
        "    bp_out = {\"LM stat\":bp_test[0], \"LM pvalue\":bp_test[1], \"F stat\":bp_test[2], \"F pvalue\":bp_test[3]}\n",
        "    print(\"Breusch-Pagan test:\", bp_out)\n",
        "\n",
        "    # VIF for multicollinearity (compute on exog)\n",
        "    exog = model.model.exog\n",
        "    exog_names = model.model.exog_names\n",
        "    vif_df = pd.DataFrame({\n",
        "        \"variable\": exog_names,\n",
        "        \"VIF\": [variance_inflation_factor(exog, i) for i in range(exog.shape[1])]\n",
        "    }).sort_values(\"VIF\", ascending=False)\n",
        "    vif_df.to_csv(os.path.join(df_out,\"ols_vif.csv\"), index=False)\n",
        "    print(\"Saved VIF table to ols_vif.csv\")\n",
        "    return bp_out, vif_df\n",
        "\n",
        "bp_out, vif_df = ols_diagnostics(ols_model)\n",
        "print(bp_out)\n",
        "print(vif_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEYAEb41TcDv",
        "outputId": "ee2f2d20-d75b-40e2-eeb6-602d52d0556b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WLS summary:\n",
            "                             WLS Regression Results                            \n",
            "===============================================================================\n",
            "Dep. Variable:     log_num_seats_total   R-squared:                       0.155\n",
            "Model:                             WLS   Adj. R-squared:                  0.155\n",
            "Method:                  Least Squares   F-statistic:                     1752.\n",
            "Date:                 Sun, 14 Sep 2025   Prob (F-statistic):               0.00\n",
            "Time:                         08:19:16   Log-Likelihood:            -1.9144e+05\n",
            "No. Observations:               209697   AIC:                         3.829e+05\n",
            "Df Residuals:                   209674   BIC:                         3.832e+05\n",
            "Df Model:                           22                                         \n",
            "Covariance Type:             nonrobust                                         \n",
            "==================================================================================================\n",
            "                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Intercept                         -0.9464      0.036    -26.486      0.000      -1.016      -0.876\n",
            "C(Customer_Cat)[T.B]               2.5221      0.033     76.757      0.000       2.458       2.586\n",
            "C(Train_Number_All)[T.B]           0.1110      0.007     15.609      0.000       0.097       0.125\n",
            "C(Train_Number_All)[T.C]           0.0565      0.007      7.598      0.000       0.042       0.071\n",
            "C(Train_Number_All)[T.D]          -0.0271      0.008     -3.569      0.000      -0.042      -0.012\n",
            "C(Train_Number_All)[T.E]           0.1607      0.006     25.252      0.000       0.148       0.173\n",
            "C(Train_Number_All)[T.F]           0.1104      0.007     16.625      0.000       0.097       0.123\n",
            "C(Train_Number_All)[T.G]           0.0776      0.007     10.831      0.000       0.064       0.092\n",
            "C(Train_Number_All)[T.H]           0.1026      0.007     15.363      0.000       0.089       0.116\n",
            "C(Train_Number_All)[T.I]           0.0077      0.007      1.044      0.297      -0.007       0.022\n",
            "C(Train_Number_All)[T.J]           0.0095      0.007      1.389      0.165      -0.004       0.023\n",
            "C(Train_Number_All)[T.K]          -0.0771      0.008     -9.123      0.000      -0.094      -0.061\n",
            "C(Train_Number_All)[T.L]          -0.0123      0.008     -1.540      0.124      -0.028       0.003\n",
            "C(Train_Number_All)[T.M]          -0.1022      0.007    -14.252      0.000      -0.116      -0.088\n",
            "C(Train_Number_All)[T.N]          -0.2154      0.011    -20.426      0.000      -0.236      -0.195\n",
            "C(Train_Number_All)[T.O]          -0.3961      0.400     -0.991      0.322      -1.180       0.388\n",
            "log_price                          0.2032      0.006     33.670      0.000       0.191       0.215\n",
            "log_price:C(Customer_Cat)[T.B]    -0.3896      0.006    -67.223      0.000      -0.401      -0.378\n",
            "days_to_departure                 -0.0002   7.61e-05     -2.875      0.004      -0.000   -6.96e-05\n",
            "I(days_to_departure ** 2)       3.981e-06   3.02e-07     13.166      0.000    3.39e-06    4.57e-06\n",
            "isNormCabin                        0.0049      0.004      1.255      0.210      -0.003       0.013\n",
            "isReturn                           0.0294      0.004      6.998      0.000       0.021       0.038\n",
            "isOneway                          -0.1117      0.004    -28.673      0.000      -0.119      -0.104\n",
            "==============================================================================\n",
            "Omnibus:                    19592.084   Durbin-Watson:                   1.754\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            25547.391\n",
            "Skew:                           0.844   Prob(JB):                         0.00\n",
            "Kurtosis:                       3.274   Cond. No.                     4.28e+06\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 4.28e+06. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 6) WLS (as a robustness check)\n",
        "# ---------------------------\n",
        "# We'll weight by inverse variance approximation: 1/(fitted^2 + c)\n",
        "fitted = ols_model.fittedvalues\n",
        "wls_model = smf.wls(formula=formula_ols, data=ols_df, weights=1/(np.exp(fitted)**2 + 1)).fit()\n",
        "print(\"WLS summary:\")\n",
        "print(wls_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUDQSNYnToIl",
        "outputId": "665bca12-610b-4eef-9e19-c20ddbfa45f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Poisson summary snippet:\n",
            "==================================================================================================\n",
            "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Intercept                         -1.6032      0.059    -26.990      0.000      -1.720      -1.487\n",
            "C(Customer_Cat)[T.B]               3.3300      0.058     57.464      0.000       3.216       3.444\n",
            "C(Train_Number_All)[T.B]           0.1942      0.008     23.720      0.000       0.178       0.210\n",
            "C(Train_Number_All)[T.C]           0.1092      0.009     11.655      0.000       0.091       0.128\n",
            "C(Train_Number_All)[T.D]          -0.0004      0.009     -0.045      0.964      -0.019       0.018\n",
            "C(Train_Number_All)[T.E]           0.2351      0.007     31.907      0.000       0.221       0.249\n",
            "C(Train_Number_All)[T.F]           0.1495      0.008     18.959      0.000       0.134       0.165\n",
            "C(Train_Number_All)[T.G]           0.1388      0.008     16.547      0.000       0.122       0.155\n",
            "C(Train_Number_All)[T.H]           0.1587      0.008     20.384      0.000       0.143       0.174\n",
            "C(Train_Number_All)[T.I]           0.0384      0.009      4.351      0.000       0.021       0.056\n",
            "C(Train_Number_All)[T.J]           0.0190      0.009      2.171      0.030       0.002       0.036\n",
            "C(Train_Number_All)[T.K]          -0.0642      0.011     -5.624      0.000      -0.087      -0.042\n",
            "C(Train_Number_All)[T.L]          -0.0099      0.012     -0.833      0.405      -0.033       0.013\n",
            "C(Train_Number_All)[T.M]          -0.1274      0.010    -12.946      0.000      -0.147      -0.108\n",
            "C(Train_Number_All)[T.N]          -0.2829      0.019    -14.663      0.000      -0.321      -0.245\n",
            "C(Train_Number_All)[T.O]          -0.5419      1.000     -0.542      0.588      -2.502       1.418\n",
            "log_price                          0.3297      0.010     32.806      0.000       0.310       0.349\n",
            "log_price:C(Customer_Cat)[T.B]    -0.5172      0.010    -51.659      0.000      -0.537      -0.498\n",
            "days_to_departure                  0.0011   7.36e-05     14.712      0.000       0.001       0.001\n",
            "I(days_to_departure ** 2)      -9.335e-07   2.66e-07     -3.503      0.000   -1.46e-06   -4.11e-07\n",
            "isNormCabin                        0.0036      0.004      0.844      0.399      -0.005       0.012\n",
            "isReturn                           0.0215      0.005      4.682      0.000       0.012       0.030\n",
            "isOneway                          -0.0930      0.005    -20.324      0.000      -0.102      -0.084\n",
            "==================================================================================================\n",
            "Negative Binomial summary snippet:\n",
            "==================================================================================================\n",
            "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Intercept                         -1.5198      0.095    -16.041      0.000      -1.706      -1.334\n",
            "C(Customer_Cat)[T.B]               3.2426      0.091     35.609      0.000       3.064       3.421\n",
            "C(Train_Number_All)[T.B]           0.1767      0.015     11.865      0.000       0.148       0.206\n",
            "C(Train_Number_All)[T.C]           0.0993      0.017      5.975      0.000       0.067       0.132\n",
            "C(Train_Number_All)[T.D]          -0.0159      0.017     -0.945      0.345      -0.049       0.017\n",
            "C(Train_Number_All)[T.E]           0.2251      0.013     16.861      0.000       0.199       0.251\n",
            "C(Train_Number_All)[T.F]           0.1439      0.014     10.124      0.000       0.116       0.172\n",
            "C(Train_Number_All)[T.G]           0.1240      0.015      8.159      0.000       0.094       0.154\n",
            "C(Train_Number_All)[T.H]           0.1467      0.014     10.411      0.000       0.119       0.174\n",
            "C(Train_Number_All)[T.I]           0.0229      0.016      1.446      0.148      -0.008       0.054\n",
            "C(Train_Number_All)[T.J]           0.0146      0.015      0.940      0.347      -0.016       0.045\n",
            "C(Train_Number_All)[T.K]          -0.0792      0.020     -3.995      0.000      -0.118      -0.040\n",
            "C(Train_Number_All)[T.L]          -0.0124      0.020     -0.622      0.534      -0.052       0.027\n",
            "C(Train_Number_All)[T.M]          -0.1274      0.017     -7.513      0.000      -0.161      -0.094\n",
            "C(Train_Number_All)[T.N]          -0.2954      0.030     -9.840      0.000      -0.354      -0.237\n",
            "C(Train_Number_All)[T.O]          -0.5713      1.414     -0.404      0.686      -3.343       2.201\n",
            "log_price                          0.3181      0.016     19.829      0.000       0.287       0.350\n",
            "log_price:C(Customer_Cat)[T.B]    -0.5010      0.016    -31.626      0.000      -0.532      -0.470\n",
            "days_to_departure                  0.0008      0.000      5.476      0.000       0.000       0.001\n",
            "I(days_to_departure ** 2)        2.99e-07   5.21e-07      0.574      0.566   -7.22e-07    1.32e-06\n",
            "isNormCabin                        0.0054      0.008      0.685      0.493      -0.010       0.021\n",
            "isReturn                           0.0275      0.009      3.224      0.001       0.011       0.044\n",
            "isOneway                          -0.1086      0.008    -13.057      0.000      -0.125      -0.092\n",
            "==================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 7) Count models: Poisson & Negative Binomial with same controls\n",
        "# ---------------------------\n",
        "# Build count formula from the OLS formula: replace dependent var\n",
        "formula_count = formula_ols.replace(\"log_num_seats_total ~\", \"num_seats_total ~\")\n",
        "\n",
        "# Fit Poisson\n",
        "pois_model = smf.glm(formula=formula_count, data=df, family=sm.families.Poisson()).fit()\n",
        "print(\"Poisson summary snippet:\")\n",
        "print(pois_model.summary().tables[1])\n",
        "\n",
        "# Fit Negative Binomial\n",
        "nb_model = smf.glm(formula=formula_count, data=df, family=sm.families.NegativeBinomial()).fit()\n",
        "print(\"Negative Binomial summary snippet:\")\n",
        "print(nb_model.summary().tables[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiynpneMTwD8",
        "outputId": "0af167e5-6ca3-4b4c-faf4-35228a8257a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fit statistics:\n",
            "                    AIC           BIC  Dispersion  Pseudo-R2\n",
            "OLS      389008.325168  3.892442e+05    1.000000        NaN\n",
            "Poisson  773206.436506 -2.333290e+06    1.515107  -1.819146\n",
            "NegBin   849744.812751 -2.507810e+06    0.435323 -10.630563\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 8) Overdispersion & fit stats\n",
        "# ---------------------------\n",
        "def fit_stats(model):\n",
        "    pearson_chi2 = np.sum(model.resid_pearson**2)\n",
        "    dispersion = pearson_chi2 / model.df_resid\n",
        "    llf = model.llf\n",
        "    ll_null = model.null_deviance / -2 if hasattr(model, \"null_deviance\") else np.nan\n",
        "    pseudo_r2 = 1 - (llf / ll_null) if ll_null not in [0, np.nan] else np.nan\n",
        "    return {\"AIC\": model.aic, \"BIC\": model.bic, \"Dispersion\": dispersion, \"Pseudo-R2\": pseudo_r2}\n",
        "\n",
        "fs_ols = fit_stats(ols_model)  # note: pseudo-R2 not meaningful here but we compute same fields\n",
        "fs_pois = fit_stats(pois_model)\n",
        "fs_nb = fit_stats(nb_model)\n",
        "\n",
        "fit_df = pd.DataFrame([fs_ols, fs_pois, fs_nb], index=[\"OLS\",\"Poisson\",\"NegBin\"])\n",
        "fit_df.to_csv(os.path.join(OUT,\"model_fit_stats.csv\"))\n",
        "print(\"Fit statistics:\\n\", fit_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcyZLMLlT53U",
        "outputId": "790dd9fd-26cd-4587-e2c4-f3cf56aa0cb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved regression comparison table to /mnt/data/gp1_outputs/regression_comparison.html\n",
            "Saved model summaries to text files.\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 9) Model comparison table + save\n",
        "# ---------------------------\n",
        "models = [ols_model, pois_model, nb_model]\n",
        "model_names = [\"OLS (log-log)\", \"Poisson\", \"NegBin\"]\n",
        "\n",
        "reg_table = summary_col(models, stars=True, float_format=\"%0.3f\",\n",
        "                        model_names=model_names,\n",
        "                        info_dict={'AIC': lambda x: f\"{x.aic:.0f}\",\n",
        "                                   'BIC': lambda x: f\"{x.bic:.0f}\"})\n",
        "# Save HTML and text\n",
        "html_path = os.path.join(OUT,\"regression_comparison.html\")\n",
        "with open(html_path, \"w\") as f:\n",
        "    f.write(reg_table.as_html())\n",
        "print(\"Saved regression comparison table to\", html_path)\n",
        "\n",
        "# Also save text summaries\n",
        "with open(os.path.join(OUT,\"nb_summary.txt\"), \"w\") as f:\n",
        "    f.write(nb_model.summary().as_text())\n",
        "with open(os.path.join(OUT,\"ols_summary.txt\"), \"w\") as f:\n",
        "    f.write(ols_model.summary().as_text())\n",
        "\n",
        "print(\"Saved model summaries to text files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9wdML6uZUBPT",
        "outputId": "07fdedb1-2806-404c-d7a1-4978679cc593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved CV results (sample) to cv_results_sample.csv\n",
            "            Model       MAE      RMSE\n",
            "0  OLS (exp pred)  1.213785  2.054918\n",
            "1         Poisson  1.308499  1.990711\n",
            "2          NegBin  1.308595  1.991221\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 10) Prediction & Out-of-sample validation (CV)\n",
        "# ---------------------------\n",
        "# A 5-fold CV on a sample to speed up (we can increase sample size)\n",
        "cv_sample_size = min(len(df), 20000)\n",
        "df_cv = df.sample(n=cv_sample_size, random_state=42).reset_index(drop=True)\n",
        "\n",
        "def cv_eval(formula, df_data, family=None, K=5):\n",
        "    kf = KFold(n_splits=K, shuffle=True, random_state=1)\n",
        "    maes = []\n",
        "    rmses = []\n",
        "    for train_i, test_i in kf.split(df_data):\n",
        "        train = df_data.iloc[train_i]\n",
        "        test = df_data.iloc[test_i]\n",
        "        if family is None:\n",
        "            model = smf.ols(formula=formula, data=train).fit()\n",
        "            pred = model.predict(test)\n",
        "            # OLS predicts log seats -> exponentiate for seat counts comparison\n",
        "            # But here we compare on original counts for Poisson/NB; for OLS convert\n",
        "            pred_count = np.exp(pred)\n",
        "        else:\n",
        "            model = smf.glm(formula=formula, data=train, family=family).fit()\n",
        "            pred_count = model.predict(test)\n",
        "        y_true = test[\"num_seats_total\"]\n",
        "        maes.append(mean_absolute_error(y_true, pred_count))\n",
        "        rmses.append(np.sqrt(mean_squared_error(y_true, pred_count)))\n",
        "    return np.mean(maes), np.mean(rmses)\n",
        "\n",
        "# CV for OLS (log-log): use formula_ols and convert predictions to counts\n",
        "mae_ols, rmse_ols = cv_eval(formula_ols, df_cv, family=None, K=5)\n",
        "mae_pois, rmse_pois = cv_eval(formula_count, df_cv, family=sm.families.Poisson(), K=5)\n",
        "mae_nb, rmse_nb = cv_eval(formula_count, df_cv, family=sm.families.NegativeBinomial(), K=5)\n",
        "\n",
        "cv_results = pd.DataFrame({\n",
        "    \"Model\":[\"OLS (exp pred)\",\"Poisson\",\"NegBin\"],\n",
        "    \"MAE\":[mae_ols,mae_pois,mae_nb],\n",
        "    \"RMSE\":[rmse_ols,rmse_pois,rmse_nb]\n",
        "})\n",
        "cv_results.to_csv(os.path.join(OUT,\"cv_results_sample.csv\"), index=False)\n",
        "print(\"Saved CV results (sample) to cv_results_sample.csv\")\n",
        "print(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zITCntT8UHac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47eb4cf-ba9f-4c12-a589-b6ab53a16dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revenue simulation saved.\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# 11) Revenue simulation (for policy insight)\n",
        "# ---------------------------\n",
        "def revenue_simulation(model, baseline_row, price_grid, mode=\"count_model\"):\n",
        "    # baseline_row: dict with median/mode covariates\n",
        "    preds = []\n",
        "    for p in price_grid:\n",
        "        row = baseline_row.copy()\n",
        "        row[\"mean_net_ticket_price\"] = p\n",
        "        row[\"log_price\"] = np.log(p)\n",
        "        df_row = pd.DataFrame([row])\n",
        "        pred = model.predict(df_row)[0]\n",
        "        if mode == \"ols_log\":\n",
        "            pred = np.exp(pred)  # convert log(seats) to seats\n",
        "        revenue = pred * p\n",
        "        preds.append({\"price\":p, \"pred_seats\":pred, \"pred_revenue\":revenue})\n",
        "    return pd.DataFrame(preds)\n",
        "\n",
        "# baseline: median numeric values and most common categorical for categorical controls\n",
        "medians = df.median(numeric_only=True).to_dict()\n",
        "# for categorical, choose mode\n",
        "modes = {}\n",
        "for col in [\"Customer_Cat\",\"booking_window\",\"Train_top30\",\"Train_Number_All\",\"isOneway\",\"isReturn\",\"isNormCabin\"]:\n",
        "    if col in df.columns:\n",
        "        modes[col] = df[col].mode().iloc[0]\n",
        "# combine\n",
        "baseline = medians.copy()\n",
        "baseline.update({k:modes.get(k, baseline.get(k, np.nan)) for k in modes.keys()})\n",
        "\n",
        "price_grid = np.linspace(df[\"mean_net_ticket_price\"].quantile(0.05),\n",
        "                         df[\"mean_net_ticket_price\"].quantile(0.95), 50)\n",
        "\n",
        "rev_nb = revenue_simulation(nb_model, baseline, price_grid, mode=\"count_model\")\n",
        "rev_nb.to_csv(os.path.join(OUT,\"revenue_sim_nb.csv\"), index=False)\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(rev_nb[\"price\"], rev_nb[\"pred_revenue\"])\n",
        "plt.xlabel(\"Price\")\n",
        "plt.ylabel(\"Predicted revenue\")\n",
        "plt.title(\"Predicted revenue vs price (Negative Binomial)\")\n",
        "plt.savefig(os.path.join(OUT,\"revenue_vs_price_nb.png\"), bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "print(\"Revenue simulation saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 12) Bootstrap CI for price elasticity (NB model)\n",
        "# ---------------------------\n",
        "def bootstrap_coef(model_formula, df_full, param=\"log_price\", family=sm.families.NegativeBinomial(), B=200, sample_frac=1.0):\n",
        "    np.random.seed(1)\n",
        "    coefs = []\n",
        "    n = len(df_full)\n",
        "    for i in range(B):\n",
        "        sample = df_full.sample(frac=sample_frac, replace=True)\n",
        "        try:\n",
        "            m = smf.glm(formula=model_formula, data=sample, family=family).fit()\n",
        "            coefs.append(m.params.get(param, np.nan))\n",
        "        except Exception:\n",
        "            coefs.append(np.nan)\n",
        "    coefs = np.array([c for c in coefs if not np.isnan(c)])\n",
        "    return np.percentile(coefs, [2.5,50,97.5]), coefs.mean()\n",
        "\n",
        "ci, mean_coef = bootstrap_coef(formula_count, df.sample(n=min(50000,len(df)), random_state=2), param=\"log_price\", B=200)\n",
        "print(\"Bootstrap (NB) 95% CI for log_price:\", ci, \"mean:\", mean_coef)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MBRrm6WUshS",
        "outputId": "2bf03531-d639-4f1b-b210-301f2b3ffad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap (NB) 95% CI for log_price: [0.24736211 0.28532666 0.32780445] mean: 0.2860535106997713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 13) Save key figures & output list for report\n",
        "# ---------------------------\n",
        "# Files written during the run are in OUT. Let's create an index file listing the important outputs to include in the report.\n",
        "files = [f for f in os.listdir(OUT)]\n",
        "with open(os.path.join(OUT,\"outputs_index.txt\"), \"w\") as f:\n",
        "    f.write(\"Outputs generated for report:\\n\\n\")\n",
        "    for fn in sorted(files):\n",
        "        f.write(fn + \"\\n\")\n",
        "print(\"Wrote outputs index to:\", os.path.join(OUT,\"outputs_index.txt\"))\n",
        "\n",
        "# End of full pipeline\n",
        "print(\"All done. Output files are in folder:\", OUT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0vZnc5iVUcM",
        "outputId": "abd5229b-2c1b-4707-93b1-30faee5ad526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote outputs index to: /mnt/data/gp1_outputs/outputs_index.txt\n",
            "All done. Output files are in folder: /mnt/data/gp1_outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yo7tTSaOWNaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5/RSuaVIzFKZoV5lELK1A",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}